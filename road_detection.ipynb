{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n-seg.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolo11n-seg.yaml\").load(\"yolo11n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/home/m4rc/Desktop/vc_final_assignament/Dataset/Cityscapes.v10i.yolov11/data.yaml\", epochs=200, imgsz=640, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/home/m4rc/Desktop/vc_final_assignament/runs/segment/train3/weights/best.pt')\n",
    "\n",
    "video_path = '/home/m4rc/Desktop/vc_final_assignament/video_demo.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error al abrir el video: {video_path}\")\n",
    "    exit()\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter('resultado_segmentacion.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Realiza la inferencia (image-size por defecto = 640 o lo que tenga el modelo)\n",
    "    # Ajusta conf según tus necesidades\n",
    "    results = model.predict(frame, conf=0.25)\n",
    "    \n",
    "    seg_result = results[0]\n",
    "    seg_masks = seg_result.masks  # Instancias de segmentación\n",
    "\n",
    "    if seg_masks is not None:\n",
    "        for mask_tensor in seg_masks.data:\n",
    "            # 1) Convertimos el tensor a numpy\n",
    "            mask = mask_tensor.cpu().numpy()\n",
    "            # mask tiene forma (redimensionada_altura, redimensionada_ancho)\n",
    "\n",
    "            # 2) Redimensionamos la máscara al tamaño original del frame\n",
    "            mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]),\n",
    "                                      interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # 3) Convertimos a booleano\n",
    "            mask_bool = mask_resized.astype(bool)\n",
    "\n",
    "            # 4) Definimos color y transparencia\n",
    "            color = (0, 255, 0)\n",
    "            alpha = 0.4\n",
    "\n",
    "            # 5) Sobreponemos la máscara con alpha blending\n",
    "            frame[mask_bool] = frame[mask_bool] * (1 - alpha) + np.array(color) * alpha\n",
    "\n",
    "    cv2.imshow('Segmentacion YOLOv8', frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
